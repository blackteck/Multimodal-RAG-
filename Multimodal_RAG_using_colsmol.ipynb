{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhIEkoYkB70AoyTbv505mg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wL-yoqHbBJw"
      },
      "source": [
        "# installation and models importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "17u-RYfNaO4S",
        "outputId": "4ea5dae9-6821-4d5e-bd44-f349ea3b7fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.9/517.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for Byaldi (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 1s (195 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/sergiopaniego/byaldi.git@colsmolvlm-support\n",
        "!apt-get install -y poppler-utils\n",
        "!pip install -q pdf2image\n",
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "from google.colab import files\n",
        "from transformers import Idefics3ForConditionalGeneration, AutoProcessor\n",
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702,
          "referenced_widgets": [
            "4c69935216e7439faaacf19face9efdd",
            "ec94ec56693d4e2ba7acdeb07772280a",
            "20de207679404cf098463e380f974e30",
            "546246a13a654dac9a85a2a72d47d315",
            "2661b249da224af2a48d741699772552",
            "b226bbffe32044c3bef16f923b1eb5f7",
            "4033db29165e433faf504b858c9dbc8a",
            "c097ee6432a44c30af1c062418e3c91a",
            "013e906d8c21452dbd12bbac4dac5eec",
            "f4044dbb22bf4b21b560002362dd3c36",
            "96d95e10996245ab8cabbc4f4582c504",
            "640cf80c87664fe7aaa60eb290ca6937",
            "4134375346c04fdbb95fd03a3b2118f3",
            "c727b901d87c49d79135c9f440b6b92a",
            "a17205d6eaf64b3297ec63727bec82ac",
            "2fa98d74681a486aaa36aca288d15d99",
            "536c7a7a61e4451d958dd782c7a60a31",
            "fe9274cf74294e7d9932e9bbd02f2763",
            "f77f1f9fa2d5490f85994ad20aa5fc22",
            "0ae781458c2641b994366127a865e66b",
            "c31418c2e5d645898f00b47405852e5b",
            "767a399bfac34d7196e66c1d8ed2af4f",
            "e81fa7ca19c647ebb0f2fb8565cbbafc",
            "4dc308615c524e2f912dbc9155e940e2",
            "79734b11dc1e4c9c82718a6714f7daac",
            "165aa347e7ae45d6aee1897f34e0c3d8",
            "06469634e54b436893d05a99ae36c2ab",
            "29e3105af748434ca63ed7e77fa803e0",
            "688a9d338d3c48278ecb1f5fb8daabdc",
            "0c08c6731b944c6da37c346a329473d5",
            "8bab16c654de4b559d6405982e490717",
            "7ee6f56801f64f6fb777a2c2bed3b4b5",
            "8edf294c18aa4df7b899a26705c68ae9",
            "b4c96e62daf241b6b621a4b4b2c04a18",
            "8860da44ecdf445f837665475d8f7c95",
            "f4f8c3904cd14148a1d403cfe4da548c",
            "89b2b28126574dbe81eea3a2c3d0de76",
            "9938f0b4431d4578bd8fd836651bdc1a",
            "3083f0d0fdbc449a94ac11306f133047",
            "4a2b173ec3ab4cdab533df7fa53357f9",
            "587f12da7fc44b878251c90aa591d392",
            "9e2651d5f0c645a381229f7227e5545c",
            "ae352211f77a41d7bdffb783d3c39511",
            "d0492eb76f27437e97221238b54ab2e7",
            "ffc4ce569e814cfbac55f4d073f403e8",
            "b0c2dd001d984bcbbf006c78ed1e415f",
            "30b01994804f4a8d95a5ee256c75c1fb",
            "929d39ba15934fe2b26ce636368c4dc0",
            "42b3c4f98aac40d1a6a303c11eb97e55",
            "fa27830536e9493c9a176494494a05b6",
            "6c6d2549641b4f0e997a242599805e00",
            "b91dfd023a324b40ae32a22ef03c3a82",
            "d815dd6301fa4fb5b0ec77d763ea08f0",
            "6341c507d0ad4f8ca5935464406f5854",
            "d1c9e152ca5748f9a0502e2203b8be97",
            "1ad7d98f6be143c793720958ebfc8c9e",
            "7af1909efa444a65851af0ffcee620ba",
            "c737a4ece9be4e87b8cabad97068de0c",
            "708e8f5fc0064485beb645d868a07cc3",
            "86570bb54e4843ea83404455b8be9665",
            "2145589492df4509b0472b862d717fb6",
            "1191f12637f241b28425674a65bd5388",
            "8a2859092bf84eadb683a4ac0a97e889",
            "d687c30e9684448fb68b5ab198bfbd18",
            "2cbe41a3ece84f07a1c3c01687fdf8e5",
            "dba42010053947b48f7df87599c058ca",
            "231e63c1550b47bb93c0a6f761cee685",
            "568b20fdde834cf9b94bb3c6a9d0af28",
            "9d0fa823e7624328abe3991c32db3195",
            "8bfbd27857884a92a4504a255629574c",
            "2671516ce50b41d9b1021077871079fe",
            "ec7cee583fbf48ce9010b5dab77f07f5",
            "590ebf2b93c84f79ba250cdb7e722a69",
            "08139ef2c673401288486815351b1ff6",
            "d54101385d974f36962ee92627a37fc5",
            "eb0b15425b79400895929efaab7eac94",
            "4eae0b6a50fb4d4cabde6741eb6cf20b",
            "99cedc1a61374ddfabc133b5cd14b4b2",
            "a89d43559f7c477c857fda8233490b5c",
            "732559e888614c4b9ea20ed67fda907e",
            "b330d2d7c42c4bbfad1a352ca096f61a",
            "3ed0ad3e681842c091f76c29d71f20ce",
            "7ff72f0737634010868d1f113da22758",
            "2ea571c4c05143cc9106551e22fac425",
            "fab437327570426f977d935cb432b02d",
            "60e8c59bab1a4fe292ef01de72236527",
            "5a1869adf06b45b2929698df020c0213",
            "b6d9a96288584958aa6563c7adcf022d",
            "4d7dc27519d34cee8c427ce45b63ea2a",
            "067d65e660ca4f8499a5e2eae9249ba7",
            "d467075fe41246d9af1b32915d9414f3",
            "c9208af239c54b33a3dca161645f7705",
            "0c897f36aabb4ef39bb0bb81d0a24ba0",
            "2bce552f32424e9395b064ed04339598",
            "ed5c145f7ae8462ca5b8f953b8c8b69c",
            "a597f05ea47847b392802efb767e145b",
            "d00c35e114d84da4bfa319aca0ab9780",
            "561d5fd45a4d4f5c88e45481429191cb",
            "f95dbc46536748669b319d5b947932b0",
            "80d37b8d296442188fd66486b796b17f",
            "05c0b622a78b4af9b08478f3df01f33a",
            "709889b452034f3b96169abb58a461a8",
            "0e8bf030595f4f8e9f5450e800f01493",
            "de9fa33d29b04a718ce8e51b2ac1d552",
            "e75d8108fbaf41488c2bbb813188c729",
            "6efc7485b3c748fba5ab8fc8616a0797",
            "2d381551194241f2a30a58962198d974",
            "1fbc8aec040342ceb877763dd8de3596",
            "7b315aab8ef5429789b19367dfc108b6",
            "c82c126dee7b426a8226d73e2469be24",
            "afd147ba9df54032b1de7003c5e2a979",
            "310879be5b1c41dd84918fa994b09920",
            "938609ee4cf14594b7d3c6232dc2faf6",
            "447f616b0db74083aecf132c7654478b",
            "2a2ec269ab114e07b4ae2cfb4b69e500",
            "ae3e1daf55c545a29dedb2f864a0369d",
            "cf2f5bfa3eb343f2a85bc978f85f7389",
            "803483c23d294929ae7e1def4bcb247c",
            "e7e7863064444f899d72fed43d7f7097",
            "b530b2d32f594922bcbec7654c95d72e",
            "402ea763d40a4d1f90681d096869ea95",
            "dfb7c261139646d38b0c0f12ce50be22",
            "4c6f71dcf0894bd0b3340fc0e19d40d1",
            "353a33109fde4386adb488ae4ad6c7e2",
            "6e35ca17d2d545bca658afa6c225c474",
            "e89ae668188044b183547f4e78b08ccc",
            "c0f351fca8ca42199e002b3c6e8165bf",
            "51fe5806be724200af2a208cad091b96",
            "5daec32b210343ce9ed44ff58824e2cc",
            "aba9dad9d6d44030bff8ac8959c458d5",
            "371a82ae48d84f4c8b6b410c308cf2c1",
            "49146c9e732148b9a5b3a31d095c582b",
            "c9d98caae2ad43f5b25d9972097b53e2",
            "ea8fa8eee5714140afa6e4463cf5f233",
            "f52a4e5e674b4b4fa0360595fd721dc2",
            "6948dc52f1984d34b477d0bee2ad1d6d",
            "1049545c66624aca85ab914336ef26d7",
            "53d208d8915246fb980cc6654927ae6f",
            "ecaccf12b40344e1aa1d324bcbf78ec6",
            "8c24623dbae84ab4861720541b7bc988",
            "02fba64673ab47d2ac6e9767bd12c7dd",
            "551eb029f32a4c0385e6dbb7d7d27544",
            "89645e511f31405484372811238a89f3",
            "93785601ca794b5ea3567d750eb41ea0",
            "9f60c027f3994f3fba1cfd8ea56427aa",
            "0ebacdb0af5642309fde9b6d6b572520",
            "f29b69578b9f4169bb52220d3ed0df79",
            "57c66d827e9d467281f7b0ebe717ad58",
            "c6dfd6b2834b44d5b01dfeff089ac6ea",
            "cbaa8fcae5014f2abdb2a4afe0769baa",
            "a8834b2f5ae84cf88a8b443dbcc4646a",
            "1de549e265c34b269463156067b81d3a",
            "21cdb6f4380a42c9b39e34d31d7807f4",
            "b2fb2b23a0684e69b649a310d868fcfd",
            "c58661b2e45b4f0fb790625dd97f36fe",
            "31f6f7bb79b84b82975fc1fcf43d792d",
            "c9bbc70a255e4de888105f623c55e60f",
            "0c6883df7fec44749e5a1d9da5966288",
            "3cef3e1e6ca240eaa00690e79279dd35",
            "080ae202d5ae4134b8db07c9c228444e",
            "03d92e176e694d3aaf2227a15382c52f",
            "415d4d87447a483d9ad42afe31d71a69",
            "d166e93bd3c24090bc566d5ac5da6cb7",
            "3bef944aed60425fad37270a18f06618",
            "da5c6b5e7fd845498a18dc99938e8930",
            "35122b98718a4069b363db05da930c33",
            "94ab9650e161404b883ecc3c8124014b",
            "9baa3718445d4c1cbcd16aa61ced892e",
            "2c441f98251c4d8cae37cada4e487742",
            "f282e76e52244be9950c1bbca1fdca7b",
            "3e9fb773cced42f99cd3c27c45925a42",
            "115077fbf15e4227a81c44da60554413",
            "26006f175f784c1d9dba8d102539a993",
            "d5dfccd8a7804573b59841bfca93fcb7",
            "52478537b59d4261b3e9ce28cff15dea",
            "07002de52ad94cc78b0e00fd78c89770",
            "fb5dbf18cce04eaea5749bc15f9759fd",
            "bb3200886e2d4495a98d970d122540c4",
            "14e4e0ba3dbc4d94adc43f9980a475c3",
            "da9c9b55440a49ee804c2c9b12c470f3",
            "b231117c0991487abd32f4b463f0e0eb",
            "00690dd23cd844f5a565fe96041f265e",
            "2429aca588d241ed9e4638f58b8c2cf9",
            "9a04a8e70740400abc385fd70775b4ac",
            "e2124a32b48c409fa6bc379193e105b5",
            "022d287adb08451f8f17d6781fc7d706",
            "ac82cf26b45a4947b22d95e0bac5c8da"
          ]
        },
        "collapsed": true,
        "id": "rSGYDFsOakqe",
        "outputId": "093a70c5-12df-4eed-e8b1-e96435a60b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c69935216e7439faaacf19face9efdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/7.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "640cf80c87664fe7aaa60eb290ca6937"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/63.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e81fa7ca19c647ebb0f2fb8565cbbafc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4c96e62daf241b6b621a4b4b2c04a18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffc4ce569e814cfbac55f4d073f403e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad7d98f6be143c793720958ebfc8c9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "231e63c1550b47bb93c0a6f761cee685"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/72.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99cedc1a61374ddfabc133b5cd14b4b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/489 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d7dc27519d34cee8c427ce45b63ea2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/4.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80d37b8d296442188fd66486b796b17f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd147ba9df54032b1de7003c5e2a979"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb7c261139646d38b0c0f12ce50be22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9d98caae2ad43f5b25d9972097b53e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93785601ca794b5ea3567d750eb41ea0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c58661b2e45b4f0fb790625dd97f36fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35122b98718a4069b363db05da930c33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb5dbf18cce04eaea5749bc15f9759fd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from byaldi import RAGMultiModalModel\n",
        "docs_retrieval_model = RAGMultiModalModel.from_pretrained(\"vidore/colsmolvlm-v0.1\")\n",
        "#torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oHbJrl1LP1Jj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "3229bb13ccf84015afe7d936fb314b9b",
            "fbfb8c07ef454128adbffdbd0baa5eb6",
            "3059d760b2a54c8390ee86e2e9b7497f",
            "eb6e03463f314b1ba5637a711d812198",
            "fc174908de394eb1b02fced494031831",
            "7bab72e73bca4511bd13da8335bda488",
            "3ff0bd1b660f42c6acea52dc69652003",
            "c9528c9c45b949edbe0c3ce10e6104d8",
            "d5e3a19ac1ce442187a8b71f6c0097e3",
            "a24d7e64728e42c6933ff2a9e3858dce",
            "8542064731b24138b36e4a36c7c857d1",
            "d4ef4800abc04b03aa6ac8cb87442e7a",
            "0613946510fe4c2988982e4d6d601da6",
            "2af4c94941ca47ef835643a5b6ac81fc",
            "e125ec21b5f6404697c4ea69ab8e6b31",
            "57babd1da9e74390bc38202c345fae80",
            "02afe3aeb6ae484eacb3a5c829b70a82",
            "36783e323446404db6f1c2eccb7234ca",
            "e876bce15f1648e98637a64ffff9de12",
            "0dfc6e7a8be2435dbdd591022be811cc",
            "58d5199561bf43c2b7883aaceb793b0a",
            "293661cea3b1481d8c34f1c42962b99b",
            "4db1dfe8fa794362b27979505958dd6f",
            "7d3b8594a1dd4504a7328445312f68ef",
            "8bca0d9e75764d9cb4e45a484348fc6f",
            "a9357d801817449aa06317098f201d60",
            "4e75dab0d94c4ad1800d997c5f2582a0",
            "bc836263b6ea4a868db171d6fbc8125b",
            "ea6e840d0fc4456c9733f5a19f5ac875",
            "25f6d8eb5b014b618ee0d1283f824e14",
            "1a360b550ba74e669d33519f17162ff3",
            "a97ceb97c82c441b91de17bcd44b6da7",
            "9dddb787a36d40a2b7bfc7282a5ef54d",
            "3bf77fb078c240188419c5dbdb082b20",
            "32219a311aec4583a643cc1fa606d791",
            "7961202ff82047aa9c9f383139c6ccbb",
            "69fafd8646034333ab8613806cf1fe55",
            "001c6c1f05bd4e8dad6bd8d47d352955",
            "f112c637ae4140ccb31db5acdecec737",
            "f5b45311f0364b208ae90fa007b832a8",
            "a52ae2ae0d654823baad31726e5788df",
            "09b33150d6fa4cd7946d5dc952b3c3ec",
            "91917935e1f3421d93594683b96ff030",
            "5289009f7e664081b5127231a46ee790",
            "dfa94e6b58ca4879a95d0b0ba06d4dac",
            "7a1cc8255f9b4414ae60d5bc4905965b",
            "d0aec7567c6c460fa8c33eb135f279be",
            "f42accb950ae4fa0b5f5f83e5df9c725",
            "46e58973bce64a4f91776534c8493dbc",
            "9fc4e512ccbf4e0b864b4788da1d4f7c",
            "5a4d753794ec4efcbbf3757d95f420f2",
            "1965c721c2e843cb87b92cb9d1a1b66c",
            "f7a6be353a0d483bab1333c17e5560b5",
            "2e7a405f64754e32b3c82a3e358620d9",
            "99cee6d4aa2d45f6bdae0656a2eee8dc",
            "17e7e78625f040dbac3bd7f029c1a9fe",
            "290cde2e74ec4c9986e17695fe5be280",
            "5cb63401706c4f6f85f489a0c377cf86",
            "ae213c6a6f7543818d52f6f17b2e019f",
            "e50870236c5046c4834a97275596a8b9",
            "52224d4acacf4544bfed071ecbc9e869",
            "07ec19116cf1488590df8dd56c52f95d",
            "3b036f78210a4a938d26a8b4bb671a8c",
            "ae2a2e2c54d341549da09195040b9c9c",
            "c1b56d131e174a91995605026b84f2ca",
            "2c486eaeeb7541c6b50876c52186ecb0",
            "fe363038ddb445cea3c6fbc36dba9c52",
            "8b0abbefad8b41368eba5ac02476900e",
            "d82050250fad42799350a8438bab7f01",
            "5f130089d6ca4a10b8e78048f7ac88d3",
            "98b92f7068154350b82743b117fec19b",
            "5e83564562ae4f8e9e7183a5e296cd54",
            "0eaa99d9fe0a497b81f7e25094744b63",
            "39b0d0bd3bf44c9c9dd50bac30fad03a",
            "fcdf299b32b0483f89752e7b4469f7c2",
            "6de17b5b54c2486a80f8b36b657570ec",
            "7e4821de9d55464da71744271671d028",
            "dd6de5a0c82b467b897f1e4eaa6a7637",
            "c917c98b74f34f06910458be9b3b37f5",
            "13192d51dd02402d925042e1475a38a5",
            "425ad31448cd4fcfa1378b14199b3ed5",
            "9394ad3e2b3e455f8820b19ccf955e5d",
            "57e303ff61054abdab6e8c03b722599d",
            "84a0f79b16f54ca2b6f20faaf79c1809",
            "eb1f52cea0a84cfa834e1a8ba3738184",
            "baf9d97df1b4420b9da60df358e21c1a",
            "e669ef8591bc42669a061ce34695956a",
            "d45f0455c7a84cd4b419bfcb3614d24f",
            "8639a56f79b44b02839b54ddf0dc6ffa",
            "2ba5f2d91f8a435592fd144a0e6d5e88",
            "9a59a3957e264b18afa26335e1fc64c1",
            "9d33884fe19c42aca40cb775ada8262e",
            "1e4c44eb1dd54146ad803d174983ce15",
            "15955a19f98144c998dbf9bae3eae5dc",
            "09ac78d17a8242d69c3037a03063a075",
            "aeb1c82a47264cdcb677edd814e6166a",
            "88d39e0e404c42acbd9c1837905f82be",
            "cb26d0b2c39547c099d40a863ae8b0e1",
            "ad39024026374aaea9f5807e3ff0b763",
            "d301067b47694913b6054764759d26af",
            "5d99246f5ae74caea1354d62058a1e1c",
            "602daa54e2114fdaa240aa5343b89856",
            "7b314c335f9544babfecee34ed2361cd",
            "6132f230e9544a85815a04c3f8e6e487",
            "bb93e6ad8c1342959b0dfaed8bec658c",
            "609d781374f14c4aaeb556c790fd508d",
            "2d1104a4c6b044a5a1568ce7077aedf2",
            "d2a29f0da7a7481fb23c6436e06de9b2",
            "5cf8580c0364463f9e75861faddeb8eb",
            "87765782c3d74ceda3e6d72b441fa22f",
            "6cc26a41446c47b4b182e11998101058",
            "f1a0956b025c49ed8672261130b8bbd4",
            "949f85ba42c54e5d9083d2a8a441ccb4",
            "2ddbf3912f2b4f83b66ee32cdf20a006",
            "a0b158e24697456384492b5cdf1574c2",
            "8f31a132a4164239a9b9389695bb4374",
            "503df1203dee42658694dc7e5205975a",
            "44fa7b78d3614042bf63c775d8b437fb",
            "d5a60605e9094b36bf0ce122f366d8ee",
            "829a699d07294e4b96724fb89bbb7cc2",
            "0111922fa61946afb8d9834db669760b",
            "106612e858ea4602abf2d33b000e094d",
            "9d8ab919413041c8a751316d13b49360",
            "ad80e4879e4943ba96c3ee181701aeb5",
            "31beab9e1d6e4c0c8b2adb22b8e89deb",
            "66a1b5b6bc714d3abcb302f3117e8da8",
            "9b22f5b39eef48a5b7422647860cfce1",
            "dde94a83a43144b39afa9b835dbda69e",
            "054548371a9945abbda5092807e91608",
            "3f6df82cd8424555b9ef1e31cf930eb8",
            "783c707786474521bdf32a330d2b1b2c",
            "4d432dbd180140c4bc2dbf52ab0cabe1"
          ]
        },
        "outputId": "33031ec2-b90a-47e1-f91c-bac432009337"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/7.45k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3229bb13ccf84015afe7d936fb314b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.49G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4ef4800abc04b03aa6ac8cb87442e7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4db1dfe8fa794362b27979505958dd6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bf77fb078c240188419c5dbdb082b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/429 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfa94e6b58ca4879a95d0b0ba06d4dac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/486 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e7e78625f040dbac3bd7f029c1a9fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/4.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe363038ddb445cea3c6fbc36dba9c52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd6de5a0c82b467b897f1e4eaa6a7637"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8639a56f79b44b02839b54ddf0dc6ffa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d301067b47694913b6054764759d26af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cc26a41446c47b4b182e11998101058"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106612e858ea4602abf2d33b000e094d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
        "vl_model = Idefics3ForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    _attn_implementation=\"eager\",\n",
        ")\n",
        "vl_model.eval()\n",
        "\n",
        "vl_model_processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lK_mRyYzazQF"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"pdf_images\", exist_ok=True)\n",
        "all_images={}\n",
        "def process_file(pdf_file):\n",
        "    # Convert PDF to images\n",
        "    global all_images\n",
        "    images = convert_from_path(pdf_file.name)\n",
        "    for i, img in enumerate(images):\n",
        "        img_path = f\"pdf_images/page_{i+1}.png\"\n",
        "        img.save(img_path, \"PNG\")\n",
        "        print(f\"Saved: {img_path}\")\n",
        "\n",
        "    all_images = load_png_images(\"pdf_images\")\n",
        "\n",
        "    docs_retrieval_model.index(\n",
        "        input_path=\"pdf_images\", index_name=\"image_index\", store_collection_with_index=False, overwrite=True\n",
        "    )\n",
        "    return \"✅ PDF processed successfully and indexed.\"\n",
        "\n",
        "def load_png_images(image_folder):\n",
        "    png_files = [f for f in os.listdir(image_folder) if f.endswith(\".png\")]\n",
        "    global all_images\n",
        "\n",
        "    for image_id, png_file in enumerate(png_files):\n",
        "        image_path = os.path.join(image_folder, png_file)\n",
        "        image = Image.open(image_path)\n",
        "        all_images[image_id] = image\n",
        "\n",
        "    return all_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TveLO5da8szg"
      },
      "source": [
        "# k=3 sequential with gui (run this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjoxaNSr4gNS"
      },
      "outputs": [],
      "source": [
        "def multimodal_rag(text_query, image_query):\n",
        "    # Case 1: Both text and image provided\n",
        "    if text_query and image_query:\n",
        "        image = image_query.convert(\"RGB\")\n",
        "\n",
        "        # Caption the image\n",
        "        image_caption_prompt = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\"},\n",
        "                    {\"type\": \"text\", \"text\": \"What does this image describe?\"},\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        caption_text = vl_model_processor.apply_chat_template(image_caption_prompt, add_generation_prompt=True)\n",
        "        image_inputs = vl_model_processor(\n",
        "            text=caption_text,\n",
        "            images=[image],\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        caption_ids = vl_model.generate(**image_inputs, max_new_tokens=50)\n",
        "        caption_ids_trimmed = [\n",
        "            out_ids[len(in_ids):] for in_ids, out_ids in zip(image_inputs.input_ids, caption_ids)\n",
        "        ]\n",
        "        image_caption = vl_model_processor.batch_decode(caption_ids_trimmed, skip_special_tokens=True)[0]\n",
        "\n",
        "        del image_inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Use caption to retrieve documents\n",
        "        results = docs_retrieval_model.search(image_caption, k=3)\n",
        "        result_images = [all_images[res[\"doc_id\"]] for res in results]\n",
        "\n",
        "        combined_texts = []\n",
        "        for img in result_images:\n",
        "            chat_template = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": text_query},\n",
        "                    ],\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            chat_text = vl_model_processor.apply_chat_template(chat_template, add_generation_prompt=True)\n",
        "\n",
        "            inputs = vl_model_processor(\n",
        "                text=chat_text,\n",
        "                images=[img],\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(\"cuda\")\n",
        "\n",
        "            generated_ids = vl_model.generate(**inputs, max_new_tokens=300)\n",
        "            generated_ids_trimmed = [\n",
        "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "            output = vl_model_processor.batch_decode(\n",
        "                generated_ids_trimmed,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=False\n",
        "            )[0]\n",
        "\n",
        "            combined_texts.append(output)\n",
        "            del inputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Summarize combined answers\n",
        "        summarization_prompt = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Summarize the following responses into one accurate and concise answer:\\n\\n\" + \"\\n\\n\".join(combined_texts)},\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        summary_text = vl_model_processor.apply_chat_template(summarization_prompt, add_generation_prompt=True)\n",
        "        summary_inputs = vl_model_processor(\n",
        "            text=summary_text,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        summary_ids = vl_model.generate(**summary_inputs, max_new_tokens=300)\n",
        "        summary_ids_trimmed = [\n",
        "            out_ids[len(in_ids):] for in_ids, out_ids in zip(summary_inputs.input_ids, summary_ids)\n",
        "        ]\n",
        "\n",
        "        final_summary = vl_model_processor.batch_decode(\n",
        "            summary_ids_trimmed,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=False\n",
        "        )[0]\n",
        "\n",
        "        return result_images, final_summary\n",
        "\n",
        "    # Case 2: Only text query\n",
        "    elif text_query:\n",
        "        results = docs_retrieval_model.search(text_query, k=3)\n",
        "        result_images = [all_images[res[\"doc_id\"]] for res in results]\n",
        "\n",
        "        combined_texts = []\n",
        "        for img in result_images:\n",
        "            chat_template = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": text_query},\n",
        "                    ],\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            chat_text = vl_model_processor.apply_chat_template(chat_template, add_generation_prompt=True)\n",
        "\n",
        "            inputs = vl_model_processor(\n",
        "                text=chat_text,\n",
        "                images=[img],\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(\"cuda\")\n",
        "\n",
        "            generated_ids = vl_model.generate(**inputs, max_new_tokens=300)\n",
        "            generated_ids_trimmed = [\n",
        "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "            output = vl_model_processor.batch_decode(\n",
        "                generated_ids_trimmed,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=False\n",
        "            )[0]\n",
        "\n",
        "            combined_texts.append(output)\n",
        "\n",
        "            del inputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Combine and summarize\n",
        "        summarization_prompt = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Summarize the following responses into one accurate and concise answer:\\n\\n\" + \"\\n\\n\".join(combined_texts)},\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        summary_text = vl_model_processor.apply_chat_template(summarization_prompt, add_generation_prompt=True)\n",
        "        summary_inputs = vl_model_processor(\n",
        "            text=summary_text,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        summary_ids = vl_model.generate(**summary_inputs, max_new_tokens=300)\n",
        "        summary_ids_trimmed = [\n",
        "            out_ids[len(in_ids):] for in_ids, out_ids in zip(summary_inputs.input_ids, summary_ids)\n",
        "        ]\n",
        "\n",
        "        final_summary = vl_model_processor.batch_decode(\n",
        "            summary_ids_trimmed,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=False\n",
        "        )[0]\n",
        "\n",
        "        return result_images, final_summary\n",
        "\n",
        "    # Case 3: Only image query\n",
        "    elif image_query:\n",
        "        image = image_query.convert(\"RGB\")\n",
        "\n",
        "        image_caption_prompt = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\"},\n",
        "                    {\"type\": \"text\", \"text\": \"What does this image describe?\"},\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        caption_text = vl_model_processor.apply_chat_template(image_caption_prompt, add_generation_prompt=True)\n",
        "\n",
        "        image_inputs = vl_model_processor(\n",
        "            text=caption_text,\n",
        "            images=[image],\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        caption_ids = vl_model.generate(**image_inputs, max_new_tokens=50)\n",
        "\n",
        "        caption_ids_trimmed = [\n",
        "            out_ids[len(in_ids):] for in_ids, out_ids in zip(image_inputs.input_ids, caption_ids)\n",
        "        ]\n",
        "\n",
        "        image_caption = vl_model_processor.batch_decode(caption_ids_trimmed, skip_special_tokens=True)[0]\n",
        "\n",
        "        del image_inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        results = docs_retrieval_model.search(image_caption, k=3)\n",
        "        result_images = [all_images[res[\"doc_id\"]] for res in results]\n",
        "\n",
        "        return result_images, f\"🔍 Caption: {image_caption}\"\n",
        "\n",
        "    # No input case\n",
        "    else:\n",
        "        return None, \"Please provide a query.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ek-pF5j84mpB",
        "outputId": "465ac794-37de-4f09-9912-494efca1d7b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://65a97b7cc37eac607c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65a97b7cc37eac607c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: pdf_images/page_1.png\n",
            "Saved: pdf_images/page_2.png\n",
            "Saved: pdf_images/page_3.png\n",
            "Saved: pdf_images/page_4.png\n",
            "Saved: pdf_images/page_5.png\n",
            "Saved: pdf_images/page_6.png\n",
            "Saved: pdf_images/page_7.png\n",
            "Saved: pdf_images/page_8.png\n",
            "Saved: pdf_images/page_9.png\n",
            "Saved: pdf_images/page_10.png\n",
            "Indexing file: pdf_images/page_2.png\n",
            "Added page 1 of document 0 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_1.png\n",
            "Added page 1 of document 1 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_10.png\n",
            "Added page 1 of document 2 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_7.png\n",
            "Added page 1 of document 3 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_6.png\n",
            "Added page 1 of document 4 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_5.png\n",
            "Added page 1 of document 5 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_8.png\n",
            "Added page 1 of document 6 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_4.png\n",
            "Added page 1 of document 7 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_9.png\n",
            "Added page 1 of document 8 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Indexing file: pdf_images/page_3.png\n",
            "Added page 1 of document 9 to index.\n",
            "Index exported to .byaldi/image_index\n",
            "Index exported to .byaldi/image_index\n"
          ]
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🧠 Multimodal RAG with SmolVLM \")\n",
        "\n",
        "    with gr.Row():\n",
        "        pdf_file= gr.File(label=\"Upload PDF\",type=\"filepath\")\n",
        "        process_pdf_btn = gr.Button(\"process\")\n",
        "        pdf_upload_status = gr.Textbox(label=\"PDF Processing Status\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_query = gr.Textbox(label=\"Text Query\", placeholder=\"Ask a question about the document...\")\n",
        "        image_query = gr.Image(label=\"Image Query\", type=\"pil\")\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"Search\")\n",
        "\n",
        "    with gr.Row():\n",
        "        result_imgs = gr.Gallery(label=\"Top 3 Relevant Pages\", show_label=True, columns=3, rows=1)\n",
        "        result_text = gr.Textbox(label=\"Answer / Caption\", lines=10)\n",
        "\n",
        "    submit_btn.click(\n",
        "        multimodal_rag,\n",
        "        inputs=[text_query, image_query],\n",
        "        outputs=[result_imgs, result_text]\n",
        "    )\n",
        "\n",
        "    process_pdf_btn.click(\n",
        "        process_file,\n",
        "        inputs=[pdf_file],\n",
        "        outputs=[pdf_upload_status]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True,share=True)"
      ]
    }
  ]
}